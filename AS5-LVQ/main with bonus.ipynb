{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for getting dataset from file\n",
    "getData_LVQ = lambda: loadmat('lvqdata.mat')['lvqdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 2)\n"
     ]
    }
   ],
   "source": [
    "# given the assignment we know the actual labels\n",
    "# first 50 are class 1, other 50 are class 2\n",
    "actual_labels = np.array([1]*50 + [2]*50)\n",
    "print(np.shape(actual_labels))\n",
    "\n",
    "data = getData_LVQ()\n",
    "\n",
    "print(np.shape(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LVQ1(data: np.array, data_labels: np.array, K: int, learning_rate: float, epochs: int,\n",
    "         init_prototypes: np.array = None, init_prototype_labels: np.array = None):\n",
    "    N = len(data[0])  # number of features, dimensionality of data\n",
    "    P = len(data)  # number of data points\n",
    "\n",
    "    if init_prototypes is None:\n",
    "        # initialize each prototype by random selection of a data point from the corre-sponding class\n",
    "        # make sure K prototypes from each class\n",
    "\n",
    "        random_indices = []\n",
    "        for label in np.unique(data_labels):\n",
    "            label_indices = np.where(data_labels == label)[0]\n",
    "            random_indices.extend(np.random.choice(label_indices, K, replace=False))\n",
    "\n",
    "        prototypes = data[random_indices]\n",
    "        prototypes_labels = data_labels[random_indices]\n",
    "    else:\n",
    "        prototypes = init_prototypes\n",
    "        prototypes_labels = init_prototype_labels\n",
    "\n",
    "    training_error = []\n",
    "    trajectories = []\n",
    "    for prot in prototypes:\n",
    "        traj = [[prot[0]], [prot[1]]]\n",
    "        trajectories.append(traj)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        # random permutation is done on indexes instead of datapoints because its easier to handle\n",
    "        random_indexes = np.random.permutation(range(P))  # random permutation of indexes\n",
    "        n_missclassifications = 0\n",
    "        for p_idx in random_indexes:\n",
    "            x = data[p_idx]\n",
    "            # find the closest prototype (winner)\n",
    "            distances = cdist(data[[p_idx]], prototypes, 'euclidean')[0]\n",
    "            closest_prototype_index = np.argmin(distances)\n",
    "            # update the winner according to winner-takes-all\n",
    "            if data_labels[p_idx] == prototypes_labels[closest_prototype_index]:\n",
    "                prototypes[closest_prototype_index] = prototypes[closest_prototype_index] + learning_rate * (\n",
    "                            x - prototypes[closest_prototype_index])\n",
    "            else:\n",
    "                prototypes[closest_prototype_index] = prototypes[closest_prototype_index] - learning_rate * (\n",
    "                            x - prototypes[closest_prototype_index])\n",
    "                n_missclassifications = n_missclassifications + 1\n",
    "            for i, prot in enumerate(prototypes):\n",
    "                trajectories[i][0].append(prot[0])\n",
    "                trajectories[i][1].append(prot[1])\n",
    "        # training error over epochs\n",
    "        training_error.append(n_missclassifications / len(data))\n",
    "\n",
    "    return (N, P, prototypes, prototypes_labels, training_error,trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(training_error:[],epochs:int):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, epochs + 1), training_error, label='Misclassification', color='green')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Misclassification')\n",
    "    plt.title('Learning curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_data(data:np.array,prototypes:[]):\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    plot = fig.add_subplot()\n",
    "    plot.scatter(data[:, 0], data[:, 1], c=\"blue\", marker='o', label='Data Points')\n",
    "    plot.scatter(prototypes[:, 0], prototypes[:, 1], c=\"red\", marker='o', label='Prototype vectors')\n",
    "    plot.set_xlabel('X values')\n",
    "    plot.set_ylabel('Y values')\n",
    "    plot.set_title('Original data points')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingResult(data: np.array, prototypes: np.array, actual_labels: np.array, prototypes_labels: np.array):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # plot the data points for each unique label\n",
    "    for label in np.unique(actual_labels):\n",
    "        plt.scatter(data[actual_labels == label][:, 0],\n",
    "                    data[actual_labels == label][:, 1],\n",
    "                    label=f'Data Class {label}')\n",
    "\n",
    "    # plot the prototypes for each unique prototype label\n",
    "    for label in np.unique(prototypes_labels):\n",
    "        plt.scatter(prototypes[prototypes_labels == label][:, 0],\n",
    "                    prototypes[prototypes_labels == label][:, 1],\n",
    "                    marker='x', s=100, label=f'Prototype Class {label}')\n",
    "\n",
    "    plt.title(\"Data with LVQ1 labels and prototype positions\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(np.unique(actual_labels))\n",
    "prototypes_per_class = 1\n",
    "K = n_labels * prototypes_per_class\n",
    "learning_rate =  0.002\n",
    "epochs = 200\n",
    "N,P,prototypes,prototypes_labels, training_error,trajectories = LVQ1(data, actual_labels, K, learning_rate, epochs)\n",
    "\n",
    "plot_learning_curve(training_error,epochs)\n",
    "plotTrainingResult(data, prototypes, actual_labels, prototypes_labels)\n",
    "\n",
    "# b) two prototypes per class\n",
    "prototypes_per_class = 2\n",
    "K = n_labels * prototypes_per_class\n",
    "learning_rate =  0.002\n",
    "epochs = 200\n",
    "N,P,prototypes,prototypes_labels, training_error,trajectories = LVQ1(data, actual_labels, K, learning_rate, epochs)\n",
    "plot_learning_curve(training_error,epochs)\n",
    "plotTrainingResult(data, prototypes, actual_labels, prototypes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bonus\n",
    "\n",
    "def plot_trajectories(data_array, trajectories, max_epochs):\n",
    "  fig = plt.figure(figsize=(10, 8))\n",
    "  plot = fig.add_subplot()\n",
    "  plot.scatter(data_array[:,0],data_array[:,1], c=\"blue\", marker='o', label='Data Points')\n",
    "  plot.set_xlabel('X values')\n",
    "  plot.set_ylabel('Y values')\n",
    "  plot.set_title('Trajectories for Epochs: '+str(max_epochs))\n",
    "  for i, t in enumerate(trajectories):\n",
    "      x = t[0]\n",
    "      y = t[1]\n",
    "      plot.plot(x, y, marker='.', label=f'Prototype Trajectory of Prot {i}')\n",
    "  fig.legend()\n",
    "  fig.show()\n",
    "\n",
    "prototypes_per_class = 3\n",
    "K = n_labels * prototypes_per_class\n",
    "learning_rate =  0.002\n",
    "epochs = 200\n",
    "N,P,prototypes,prototypes_labels, training_error,trajectories = LVQ1(data, actual_labels, K, learning_rate, epochs)\n",
    "plot_trajectories(data,trajectories,epochs)\n",
    "plot_learning_curve(training_error,epochs)\n",
    "plotTrainingResult(data, prototypes, actual_labels, prototypes_labels)\n",
    "\n",
    "prototypes_per_class = 4\n",
    "K = n_labels * prototypes_per_class\n",
    "learning_rate =  0.002\n",
    "epochs = 200\n",
    "N,P,prototypes,prototypes_labels, training_error,trajectories = LVQ1(data, actual_labels, K, learning_rate, epochs)\n",
    "plot_trajectories(data,trajectories,epochs)\n",
    "plot_learning_curve(training_error,epochs)\n",
    "plotTrainingResult(data, prototypes, actual_labels, prototypes_labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
